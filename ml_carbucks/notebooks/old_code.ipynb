{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b271acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class BaseDetectionAdapter(ABC):\n",
    "#     \"\"\"\n",
    "#     Base class for detection model adapters.\n",
    "#     Handles:\n",
    "#       - Model creation/loading from weights\n",
    "#       - Class names\n",
    "#       - Device selection\n",
    "#       - Hyperparameters storage\n",
    "#       - Dataset paths awareness\n",
    "#       - Standard interface for training and evaluation\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         classes: List[str],\n",
    "#         model_path: Optional[Path | str] = None,\n",
    "#         device: Optional[str] = None,\n",
    "#         hparams: Optional[Dict[str, Any]] = None,\n",
    "#         datasets: Optional[\n",
    "#             Dict[str, Path | str]\n",
    "#         ] = None,  # e.g., {\"train\": \"...\", \"val\": \"...\", \"test\": \"...\"}\n",
    "#         metadata: Optional[Dict[str, Any]] = None,\n",
    "#     ):\n",
    "#         self.model_path = Path(model_path) if model_path else None\n",
    "#         self.classes = classes or []\n",
    "#         self.device = device or (\"cuda\" if self._cuda_available() else \"cpu\")\n",
    "#         self.hparams = hparams or {}\n",
    "#         self.datasets = datasets or {}\n",
    "#         self.model = None\n",
    "#         self.metadata = metadata or {}\n",
    "\n",
    "#         self.load_model()\n",
    "#         self.setup()  # Subclass decides how to implement\n",
    "\n",
    "#     # ------------------------\n",
    "#     # Abstract methods every adapter must implement\n",
    "#     # ------------------------\n",
    "#     @abstractmethod\n",
    "#     def load_model(self):\n",
    "#         \"\"\"Load model from weights or create a new model from scratch.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def setup(self):\n",
    "#         \"\"\"Initialize datasets using the provided paths.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def fit(self):\n",
    "#         \"\"\"Train the model on the training dataset.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def evaluate(self) -> Dict[str, float]:\n",
    "#         \"\"\"Evaluate the model on the designated dataset(s).\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def predict(self, images: Any) -> List[Dict[str, Any]]:\n",
    "#         \"\"\"\n",
    "#         Run full inference pipeline on a single image (or batch if desired).\n",
    "#         Must return standardized detections:\n",
    "#             [{\"bbox\": [x1, y1, x2, y2], \"score\": float, \"label\": str}, ...]\n",
    "#         \"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def save_model(self, dir: Path | str) -> Path:\n",
    "#         \"\"\"Save the model weights to the specified path.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     @abstractmethod\n",
    "#     def clone_with_params(self, params: Dict[str, Any]) -> \"BaseDetectionAdapter\":\n",
    "#         \"\"\"Create a new adapter instance with the given hyperparameters.\"\"\"\n",
    "#         pass\n",
    "\n",
    "#     # ------------------------\n",
    "#     # Optional helpers\n",
    "#     # ------------------------\n",
    "#     def to(self, device: str):\n",
    "#         \"\"\"Move model to a different device.\"\"\"\n",
    "#         self.device = device\n",
    "#         if self.model:\n",
    "#             self.model.to(device)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _cuda_available() -> bool:\n",
    "#         try:\n",
    "#             import torch\n",
    "\n",
    "#             return torch.cuda.is_available()\n",
    "#         except ImportError:\n",
    "#             return False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BaseDetectionAdapter(ABC):\n",
    "    classes: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "    hparams: Dict[str, Any] = field(default_factory=dict)\n",
    "    device: Optional[str] = None\n",
    "    model: Any = field(init=False, default=None)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.device = self.device or (\"cuda\" if self._cuda_available() else \"cpu\")\n",
    "        self.model = None\n",
    "\n",
    "        self.health_check()\n",
    "\n",
    "    # ------------------------\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_required_metadata_keys(self) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_possible_hyper_keys(self) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def setup(self) -> \"BaseDetectionAdapter\":\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self) -> \"BaseDetectionAdapter\":\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self) -> Dict[str, float]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, images: Any) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Run full inference pipeline on a single image (or batch if desired).\n",
    "        Must return standardized detections:\n",
    "            [{\"bbox\": [x1, y1, x2, y2], \"score\": float, \"label\": str}, ...]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save(self, dir: Path | str) -> Path:\n",
    "        \"\"\"Save the model weights to the specified path.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def clone(self) -> \"BaseDetectionAdapter\":\n",
    "        \"\"\"Create a new adapter instance.\"\"\"\n",
    "        pass\n",
    "\n",
    "    # ------------------------\n",
    "\n",
    "    def set_params(self, params: Dict[str, Any]) -> \"BaseDetectionAdapter\":\n",
    "        \"\"\"Set hyperparameters and return self for chaining.\"\"\"\n",
    "        if self.model is not None:\n",
    "            raise ValueError(\"Cannot set parameters after model has been created.\")\n",
    "\n",
    "        possible_keys = self.get_possible_hyper_keys()\n",
    "        for key, value in params.items():\n",
    "            if key in possible_keys:\n",
    "                self.hparams[key] = value\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid hyperparameter key: {key} for adapter {self.__class__.__name__}\"\n",
    "                )\n",
    "        return self\n",
    "\n",
    "    def get_metadata_value(self, key: str, default: Any = None) -> Any:\n",
    "        return self.metadata.get(key, default)\n",
    "\n",
    "    def get_param(self, key: str, default: Any = None) -> Any:\n",
    "        return self.hparams.get(key, default)\n",
    "\n",
    "    def health_check(self):\n",
    "        required_keys = self.get_required_metadata_keys()\n",
    "        missing_keys = [key for key in required_keys if key not in self.metadata]\n",
    "        if missing_keys:\n",
    "            raise ValueError(\n",
    "                f\"Missing required metadata keys: {missing_keys} for adapter {self.__class__.__name__}\"\n",
    "            )\n",
    "\n",
    "        possible_keys = self.get_possible_hyper_keys()\n",
    "        invalid_keys = [key for key in self.hparams if key not in possible_keys]\n",
    "        if invalid_keys:\n",
    "            raise ValueError(\n",
    "                f\"Invalid hyperparameter keys: {invalid_keys} for adapter {self.__class__.__name__}\"\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _cuda_available() -> bool:\n",
    "        try:\n",
    "            import torch\n",
    "\n",
    "            return torch.cuda.is_available()\n",
    "        except ImportError:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e91f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "from effdet import create_model, create_loader\n",
    "from effdet.data import resolve_input_config\n",
    "from effdet.anchors import Anchors, AnchorLabeler\n",
    "from timm.optim._optim_factory import create_optimizer_v2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from ml_carbucks.adapters.BaseDetectionAdapter import BaseDetectionAdapter\n",
    "from ml_carbucks.utils.coco import CocoStatsEvaluator, create_dataset_custom\n",
    "from ml_carbucks.utils.logger import setup_logger\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "\n",
    "class EfficientDetAdapter(BaseDetectionAdapter):\n",
    "\n",
    "    def get_possible_hyper_keys(self) -> List[str]:\n",
    "        return [\n",
    "            \"img_size\",\n",
    "            \"batch_size\",\n",
    "            \"epochs\",\n",
    "            \"opt\",\n",
    "            \"lr\",\n",
    "            \"weight_decay\",\n",
    "        ]\n",
    "\n",
    "    def get_required_metadata_keys(self) -> List[str]:\n",
    "        return [\n",
    "            \"version\",\n",
    "            \"train_img_dir\",\n",
    "            \"train_ann_file\",\n",
    "            \"val_img_dir\",\n",
    "            \"val_ann_file\",\n",
    "        ]\n",
    "\n",
    "    def save(self, dir: Path | str) -> Path:\n",
    "        save_path = Path(dir) / \"model.pth\"\n",
    "        torch.save(self.model.model.state_dict(), save_path)\n",
    "        return save_path\n",
    "\n",
    "    def clone(self) -> \"EfficientDetAdapter\":\n",
    "        return EfficientDetAdapter(\n",
    "            classes=self.classes,\n",
    "            metadata=self.metadata.copy(),\n",
    "            hparams=self.hparams.copy(),\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "    def predict(self, images: Any) -> List[Dict[str, Any]]:\n",
    "        raise NotImplementedError(\"Predict method is not yet implemented.\")\n",
    "\n",
    "    def setup(self) -> \"EfficientDetAdapter\":\n",
    "        img_size = self.get_param(\"img_size\")\n",
    "\n",
    "        version = self.get_metadata_value(\"version\")\n",
    "        weights = self.get_metadata_value(\"weights\", None)\n",
    "        bench_labeler = self.get_metadata_value(\"bench_labeler\", True)\n",
    "\n",
    "        # NOTE: img size would need to be updated here if we want to change it\n",
    "        # I dont think it is possible to change it after model creation\n",
    "        extra_args = dict(image_size=(img_size, img_size))\n",
    "        self.model = create_model(\n",
    "            model_name=version,\n",
    "            bench_task=\"train\",\n",
    "            num_classes=len(self.classes),\n",
    "            pretrained=weights is None,\n",
    "            checkpoint_path=weights,\n",
    "            bench_labeler=bench_labeler,\n",
    "            checkpoint_ema=False,\n",
    "            **extra_args,\n",
    "        )\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.labeler = None\n",
    "        if bench_labeler is False:\n",
    "            self.labeler = AnchorLabeler(\n",
    "                Anchors.from_config(self.model.config),\n",
    "                self.model.config.num_classes,\n",
    "                match_threshold=0.5,\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit(self) -> \"EfficientDetAdapter\":\n",
    "        logger.info(\"Starting training...\")\n",
    "        self.model.train()\n",
    "\n",
    "        batch_size = self.get_param(\"batch_size\")\n",
    "        epochs = self.get_param(\"epochs\")\n",
    "        opt = self.get_param(\"opt\", \"momentum\")\n",
    "        lr = self.get_param(\"lr\", 7e-3)\n",
    "        weight_decay = self.get_param(\"weight_decay\", 1e-5)\n",
    "\n",
    "        train_img_dir = self.get_metadata_value(\"train_img_dir\")\n",
    "        train_ann_file = self.get_metadata_value(\"train_ann_file\")\n",
    "\n",
    "        input_config = resolve_input_config(self.hparams, self.model.config)\n",
    "\n",
    "        train_dataset = create_dataset_custom(\n",
    "            img_dir=train_img_dir,\n",
    "            ann_file=train_ann_file,\n",
    "            has_labels=True,\n",
    "        )\n",
    "\n",
    "        train_loader = create_loader(\n",
    "            train_dataset,\n",
    "            input_size=input_config[\"input_size\"],\n",
    "            batch_size=batch_size,\n",
    "            is_training=True,\n",
    "            use_prefetcher=True,\n",
    "            # NOTE: currrently not used\n",
    "            # re_prob=args.reprob,\n",
    "            # re_mode=args.remode,\n",
    "            # re_count=args.recount,\n",
    "            interpolation=input_config[\"interpolation\"],\n",
    "            fill_color=input_config[\"fill_color\"],\n",
    "            mean=input_config[\"mean\"],\n",
    "            std=input_config[\"std\"],\n",
    "            num_workers=4,\n",
    "            distributed=False,\n",
    "            pin_mem=False,\n",
    "            anchor_labeler=self.labeler,\n",
    "            transform_fn=None,\n",
    "            collate_fn=None,\n",
    "        )\n",
    "\n",
    "        parser_max_label = train_loader.dataset.parser.max_label  # type: ignore\n",
    "        config_num_classes = self.model.config.num_classes\n",
    "\n",
    "        if parser_max_label != config_num_classes:\n",
    "            raise ValueError(\n",
    "                f\"Number of classes in dataset ({parser_max_label}) does not match \"\n",
    "                f\"model config ({config_num_classes}).\"\n",
    "                f\"Please verify that the dataset is curated (classes IDs start from 1)\"\n",
    "            )\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            logger.info(f\"Epoch {epoch}/{epochs}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "            optimizer = create_optimizer_v2(\n",
    "                self.model,\n",
    "                opt=opt,\n",
    "                lr=lr,\n",
    "                weight_decay=weight_decay,\n",
    "            )\n",
    "\n",
    "            for imgs, targets in tqdm(train_loader):\n",
    "                output = self.model(imgs, targets)\n",
    "                loss = output[\"loss\"]\n",
    "                total_loss += loss.item()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def evaluate(self) -> Dict[str, float]:\n",
    "        self.model.eval()\n",
    "\n",
    "        batch_size = self.get_param(\"batch_size\")\n",
    "\n",
    "        val_img_dir = self.get_metadata_value(\"val_img_dir\")\n",
    "        val_ann_file = self.get_metadata_value(\"val_ann_file\")\n",
    "\n",
    "        dataset_val = create_dataset_custom(\n",
    "            img_dir=val_img_dir,\n",
    "            ann_file=val_ann_file,\n",
    "            has_labels=True,\n",
    "        )\n",
    "\n",
    "        input_config = resolve_input_config(self.hparams, self.model.config)\n",
    "\n",
    "        val_loader = create_loader(\n",
    "            dataset_val,\n",
    "            input_size=input_config[\"input_size\"],\n",
    "            batch_size=batch_size,\n",
    "            is_training=False,\n",
    "            use_prefetcher=True,\n",
    "            interpolation=input_config[\"interpolation\"],\n",
    "            fill_color=input_config[\"fill_color\"],\n",
    "            mean=input_config[\"mean\"],\n",
    "            std=input_config[\"std\"],\n",
    "            num_workers=4,\n",
    "            distributed=False,\n",
    "            pin_mem=False,\n",
    "            anchor_labeler=self.labeler,\n",
    "            transform_fn=None,\n",
    "            collate_fn=None,\n",
    "        )\n",
    "\n",
    "        evaluator = CocoStatsEvaluator(val_loader.dataset)\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, targets in val_loader:\n",
    "                output = self.model(imgs, targets)\n",
    "                loss = output[\"loss\"]\n",
    "                total_loss += loss.item()\n",
    "                evaluator.add_predictions(output[\"detections\"], targets)\n",
    "\n",
    "        results = evaluator.evaluate()\n",
    "        metrics = {\n",
    "            \"map_50\": results[1],\n",
    "            \"map_50_95\": results[0],\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff12db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO __main__ 22:05:45 | Starting training...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO __main__ 22:05:45 | Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:48<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map_50': np.float64(0.11513648440438125),\n",
       " 'map_50_95': np.float64(0.04177036426450896)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml_carbucks import DATA_CAR_DD_DIR\n",
    "\n",
    "emodel = EfficientDetAdapter(\n",
    "    classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "    metadata={\n",
    "        \"version\": \"efficientdet_d0\",\n",
    "        \"train_img_dir\": DATA_CAR_DD_DIR / \"images\" / \"train\",\n",
    "        \"train_ann_file\": DATA_CAR_DD_DIR / \"instances_train_curated.json\",\n",
    "        \"val_img_dir\": DATA_CAR_DD_DIR / \"images\" / \"val\",\n",
    "        \"val_ann_file\": DATA_CAR_DD_DIR / \"instances_val_curated.json\",\n",
    "    },\n",
    "    hparams={\n",
    "        \"img_size\": 512,\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 8,\n",
    "        \"opt\": \"momentum\",\n",
    "        \"lr\": 8e-3,\n",
    "        \"weight_decay\": 1e-4,\n",
    "    }\n",
    ")\n",
    "\n",
    "emodel.setup()\n",
    "emodel.fit()\n",
    "eres = emodel.evaluate()\n",
    "\n",
    "eres"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-carbucks-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
