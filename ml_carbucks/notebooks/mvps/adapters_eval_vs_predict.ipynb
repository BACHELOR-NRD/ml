{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f09817",
   "metadata": {},
   "source": [
    "# Adapter eval vs predict\n",
    "\n",
    "### Introduction\n",
    "While we train the models and evaluate them, all the processes are handled by those models and methods around them. \n",
    "The real behaviour of passing data to them (from outside) is not there and may differ during inference.\n",
    "\n",
    "So it is crucial if the model will behave the same regardless of if evaluation and preprocessing is handled internally or externally.\n",
    "\n",
    "### Methodology\n",
    "We are testing if the models will produce similar MAP@50-95 results when evaluated using the `eval` method and the `predict` method.\n",
    "\n",
    "### Results\n",
    "We will run both `eval` and `predict` methods on the same dataset and compare the results. They should be very close to each other.\n",
    "\n",
    "### Discussions\n",
    "Values may differ slightly due to different thresholds used in `eval` and `predict`, but should be acceptably close (e.g., within 0.01-0.05 points - this is just an arbitrary observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fb67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:49:59 | Starting evaluation...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:49:59 | Converting COCO annotations to YOLO format...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:49:59 | COCO to YOLO conversion completed in 0.03 seconds\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:49:59 | YOLO dataset YAML created at: /home/bachelor/ml-carbucks/data/car_dd_testing/instances_val_curated.yaml\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 9181.5±1219.1 MB/s, size: 779.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/bachelor/ml-carbucks/data/car_dd_testing/labels/val.cache... 633 images, 177 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 2.7Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 14.8it/s 3.4s0.1s\n",
      "                   all        810       1406       0.43      0.399      0.375      0.199\n",
      "Speed: 0.1ms preprocess, 3.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/bachelor/ml-carbucks/runs/detect/val39\u001b[0m\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:50:05 | Starting evaluation...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:50:05 | Converting COCO annotations to YOLO format...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:50:05 | COCO to YOLO conversion completed in 0.02 seconds\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 12:50:05 | YOLO dataset YAML created at: /home/bachelor/ml-carbucks/data/car_dd_testing/instances_val_curated.yaml\n",
      "rt-detr-l summary: 302 layers, 31,989,905 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 5636.9±4108.7 MB/s, size: 756.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/bachelor/ml-carbucks/data/car_dd_testing/labels/val.cache... 633 images, 177 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 3.0Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 7.8it/s 6.5s0.1s\n",
      "                   all        810       1406      0.573      0.477      0.493      0.276\n",
      "Speed: 0.2ms preprocess, 6.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/bachelor/ml-carbucks/runs/detect/val40\u001b[0m\n",
      "INFO ml_carbucks.adapters.FasterRcnnAdapter 12:50:13 | Starting evaluation...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO ml_carbucks.ensemble.EnsembleModel 12:50:50 | Evaluating adapter: YoloUltralyticsAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:05<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 12:50:56 | Evaluating adapter: RtdetrUltralyticsAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:07<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 12:51:04 | Evaluating adapter: FasterRcnnAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:35<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 12:51:40 | Evaluating adapter: EfficientDetAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:13<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO adapter_eval_vs_predict 12:51:54 | Adapter: YoloUltralyticsAdapter\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Metrics - evaluation: 0.1994, predict: 0.1649\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Adapter: RtdetrUltralyticsAdapter\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Metrics - evaluation: 0.2758, predict: 0.2508\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Adapter: FasterRcnnAdapter\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Metrics - evaluation: 0.1037, predict: 0.0984\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Adapter: EfficientDetAdapter\n",
      "INFO adapter_eval_vs_predict 12:51:54 | Metrics - evaluation: 0.1673, predict: 0.1661\n"
     ]
    }
   ],
   "source": [
    "from ml_carbucks import DATA_DIR\n",
    "from ml_carbucks.adapters.EfficientDetAdapter import EfficientDetAdapter\n",
    "from ml_carbucks.adapters.FasterRcnnAdapter import FasterRcnnAdapter\n",
    "from ml_carbucks.adapters.UltralyticsAdapter import RtdetrUltralyticsAdapter, YoloUltralyticsAdapter\n",
    "from ml_carbucks.ensemble.EnsembleModel import EnsembleModel\n",
    "from ml_carbucks.utils.logger import setup_logger\n",
    "\n",
    "logger = setup_logger(\"adapter_eval_vs_predict\")\n",
    "\n",
    "ensemble = EnsembleModel(\n",
    "    classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "    adapters=[\n",
    "        YoloUltralyticsAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 32,\n",
    "                \"epochs\": 27,\n",
    "                \"lr\": 0.0015465639515144544,\n",
    "                \"momentum\": 0.3628781599889685,\n",
    "                \"weight_decay\": 0.0013127041660177367,\n",
    "                \"optimizer\": \"NAdam\",\n",
    "                \"verbose\": False,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_YoloUltralyticsAdaptermodel.pt\",\n",
    "        ),\n",
    "        RtdetrUltralyticsAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 16,\n",
    "                \"epochs\": 10,\n",
    "                \"lr\": 0.0001141043015859849,\n",
    "                \"momentum\": 0.424704619626319,\n",
    "                \"weight_decay\": 0.00012292547851740234,\n",
    "                \"optimizer\": \"AdamW\",\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_RtdetrUltralyticsAdaptermodel.pt\",\n",
    "        ),\n",
    "        FasterRcnnAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 8,\n",
    "                \"epochs\": 30,\n",
    "                \"lr_backbone\": 2.6373762637681257e-05,\n",
    "                \"lr_head\": 0.0011244046084737927,\n",
    "                \"weight_decay_backbone\": 0.000796017512818448,\n",
    "                \"weight_decay_head\": 0.0005747409908715994,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/FasterRcnnAdaptermodel.pth\",\n",
    "        ),\n",
    "        EfficientDetAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 8,\n",
    "                \"epochs\": 26,\n",
    "                \"optimizer\": \"momentum\",\n",
    "                \"lr\": 0.003459928723120903,\n",
    "                \"weight_decay\": 0.0001302610542371722,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_EfficientDetAdaptermodel.pth\",\n",
    "        ),\n",
    "    ],\n",
    ").setup()\n",
    "\n",
    "train_datasets = [\n",
    "    (\n",
    "        DATA_DIR / \"car_dd_testing\" / \"images\" / \"train\",\n",
    "        DATA_DIR / \"car_dd_testing\" / \"instances_train_curated.json\",\n",
    "    )\n",
    "]\n",
    "val_datasets = [\n",
    "    (\n",
    "        DATA_DIR / \"car_dd_testing\" / \"images\" / \"val\",\n",
    "        DATA_DIR / \"car_dd_testing\" / \"instances_val_curated.json\",\n",
    "    )\n",
    "]\n",
    "\n",
    "def test_eval_vs_predict(metric_name: str = \"map_50_95\"):\n",
    "    eval_metrics = ensemble.evaluate_adapters_by_evaluation_from_dataset(val_datasets)  # type: ignore\n",
    "    predict_metrics = ensemble.evaluate_adapters_by_predict_from_dataset(val_datasets)  # type: ignore\n",
    "\n",
    "    for idx, adapter in enumerate(ensemble.adapters):\n",
    "        logger.info(f\"Adapter: {adapter.__class__.__name__}\")\n",
    "        logger.info(f\"Metrics - evaluation: {round(eval_metrics[idx][metric_name], 4)}, predict: {round(predict_metrics[idx][metric_name], 4)}\") # type: ignore\n",
    "\n",
    "    return eval_metrics, predict_metrics\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m1, me2 = test_eval_vs_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-carbucks-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
