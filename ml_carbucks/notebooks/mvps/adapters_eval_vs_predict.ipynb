{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f09817",
   "metadata": {},
   "source": [
    "# Adapter eval vs predict\n",
    "TThis is to verify that eval and predict give similar results when using adapters.\n",
    "\n",
    "It is beacause the adapters use in-built image processing and data loading but what we are interesetd is if they will handle images during the real inference the same way.\n",
    "\n",
    "Values may differ slightly due to different thresholds used in eval and predict, but should be acceptably close - 0.05 map_50_90 away (arbitraty number concluded after various tests and observations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fb67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO adapter_eval_vs_predict 23:39:41 | Evaluating ensemble by evaluation from dataset\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:41 | Starting evaluation...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:41 | Converting COCO annotations to YOLO format...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:41 | COCO to YOLO conversion completed in 0.02 seconds\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:41 | YOLO dataset YAML created at: /home/bachelor/ml-carbucks/data/car_dd_testing/instances_val_curated.yaml\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 9859.3±1392.3 MB/s, size: 789.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/bachelor/ml-carbucks/data/car_dd_testing/labels/val.cache... 633 images, 177 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 3.1Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 14.8it/s 3.5s0.1s\n",
      "                   all        810       1406       0.43      0.399      0.375      0.199\n",
      "Speed: 0.1ms preprocess, 3.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/bachelor/ml-carbucks/runs/detect/val34\u001b[0m\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:46 | Starting evaluation...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:46 | Converting COCO annotations to YOLO format...\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:46 | COCO to YOLO conversion completed in 0.02 seconds\n",
      "INFO ml_carbucks.adapters.UltralyticsAdapter 23:39:46 | YOLO dataset YAML created at: /home/bachelor/ml-carbucks/data/car_dd_testing/instances_val_curated.yaml\n",
      "rt-detr-l summary: 302 layers, 31,989,905 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 6604.5±3450.1 MB/s, size: 798.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/bachelor/ml-carbucks/data/car_dd_testing/labels/val.cache... 633 images, 177 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 810/810 4.8Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 51/51 7.8it/s 6.5s0.1s\n",
      "                   all        810       1406      0.573      0.477      0.493      0.276\n",
      "Speed: 0.2ms preprocess, 6.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/bachelor/ml-carbucks/runs/detect/val35\u001b[0m\n",
      "INFO ml_carbucks.adapters.FasterRcnnAdapter 23:39:54 | Starting evaluation...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Evaluation by evaluation results:\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Adapter: YoloUltralyticsAdapter, Metrics: {'map_50': 0.37547850015394535, 'map_50_95': 0.19936537404157367}\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Adapter: RtdetrUltralyticsAdapter, Metrics: {'map_50': 0.49289777293378106, 'map_50_95': 0.27581342862762825}\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Adapter: FasterRcnnAdapter, Metrics: {'map_50': 0.2715727984905243, 'map_50_95': 0.10372346639633179}\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Adapter: EfficientDetAdapter, Metrics: {'map_50': 0.3597193956375122, 'map_50_95': 0.16730839014053345}\n",
      "INFO adapter_eval_vs_predict 23:40:32 | Evaluating ensemble by predict from dataset\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "INFO ml_carbucks.ensemble.EnsembleModel 23:40:32 | Evaluating adapter: YoloUltralyticsAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:05<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 23:40:38 | Evaluating adapter: RtdetrUltralyticsAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:08<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 23:40:46 | Evaluating adapter: FasterRcnnAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:34<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ml_carbucks.ensemble.EnsembleModel 23:41:21 | Evaluating adapter: EfficientDetAdapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:13<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO adapter_eval_vs_predict 23:41:35 | Evaluation by predict results:\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: YoloUltralyticsAdapter, Metrics: {'map_50': 0.3114479184150696, 'map_50_95': 0.1649264544248581, 'classes': [1, 2, 3]}\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: RtdetrUltralyticsAdapter, Metrics: {'map_50': 0.44884592294692993, 'map_50_95': 0.2507704794406891, 'classes': [1, 2, 3]}\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: FasterRcnnAdapter, Metrics: {'map_50': 0.25654569268226624, 'map_50_95': 0.09843528270721436, 'classes': [1, 2, 3]}\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: EfficientDetAdapter, Metrics: {'map_50': 0.3560166358947754, 'map_50_95': 0.16611579060554504, 'classes': [1, 2, 3]}\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Comparing results from both evaluation methods\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: YoloUltralyticsAdapter\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from evaluation: 0.19936537404157367\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from predict: 0.1649264544248581\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: RtdetrUltralyticsAdapter\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from evaluation: 0.27581342862762825\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from predict: 0.2507704794406891\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: FasterRcnnAdapter\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from evaluation: 0.10372346639633179\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from predict: 0.09843528270721436\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Adapter: EfficientDetAdapter\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from evaluation: 0.16730839014053345\n",
      "INFO adapter_eval_vs_predict 23:41:35 | Metrics from predict: 0.16611579060554504\n"
     ]
    }
   ],
   "source": [
    "from ml_carbucks import DATA_DIR\n",
    "from ml_carbucks.adapters.EfficientDetAdapter import EfficientDetAdapter\n",
    "from ml_carbucks.adapters.FasterRcnnAdapter import FasterRcnnAdapter\n",
    "from ml_carbucks.adapters.UltralyticsAdapter import RtdetrUltralyticsAdapter, YoloUltralyticsAdapter\n",
    "from ml_carbucks.ensemble.EnsembleModel import EnsembleModel\n",
    "from ml_carbucks.utils.logger import setup_logger\n",
    "\n",
    "logger = setup_logger(\"adapter_eval_vs_predict\")\n",
    "\n",
    "ensemble = EnsembleModel(\n",
    "    classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "    adapters=[\n",
    "        YoloUltralyticsAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 32,\n",
    "                \"epochs\": 27,\n",
    "                \"lr\": 0.0015465639515144544,\n",
    "                \"momentum\": 0.3628781599889685,\n",
    "                \"weight_decay\": 0.0013127041660177367,\n",
    "                \"optimizer\": \"NAdam\",\n",
    "                \"verbose\": False,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_YoloUltralyticsAdaptermodel.pt\",\n",
    "        ),\n",
    "        RtdetrUltralyticsAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 16,\n",
    "                \"epochs\": 10,\n",
    "                \"lr\": 0.0001141043015859849,\n",
    "                \"momentum\": 0.424704619626319,\n",
    "                \"weight_decay\": 0.00012292547851740234,\n",
    "                \"optimizer\": \"AdamW\",\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_RtdetrUltralyticsAdaptermodel.pt\",\n",
    "        ),\n",
    "        FasterRcnnAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 8,\n",
    "                \"epochs\": 30,\n",
    "                \"lr_backbone\": 2.6373762637681257e-05,\n",
    "                \"lr_head\": 0.0011244046084737927,\n",
    "                \"weight_decay_backbone\": 0.000796017512818448,\n",
    "                \"weight_decay_head\": 0.0005747409908715994,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/FasterRcnnAdaptermodel.pth\",\n",
    "        ),\n",
    "        EfficientDetAdapter(\n",
    "            classes=[\"scratch\", \"dent\", \"crack\"],\n",
    "            **{\n",
    "                \"img_size\": 384,\n",
    "                \"batch_size\": 8,\n",
    "                \"epochs\": 26,\n",
    "                \"optimizer\": \"momentum\",\n",
    "                \"lr\": 0.003459928723120903,\n",
    "                \"weight_decay\": 0.0001302610542371722,\n",
    "            },\n",
    "            weights=\"/home/bachelor/ml-carbucks/results/ensemble_demos/trial_4_EfficientDetAdaptermodel.pth\",\n",
    "        ),\n",
    "    ],\n",
    ").setup()\n",
    "\n",
    "train_datasets = [\n",
    "    (\n",
    "        DATA_DIR / \"car_dd_testing\" / \"images\" / \"train\",\n",
    "        DATA_DIR / \"car_dd_testing\" / \"instances_train_curated.json\",\n",
    "    )\n",
    "]\n",
    "val_datasets = [\n",
    "    (\n",
    "        DATA_DIR / \"car_dd_testing\" / \"images\" / \"val\",\n",
    "        DATA_DIR / \"car_dd_testing\" / \"instances_val_curated.json\",\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def test_1():\n",
    "    logger.info(\"Evaluating ensemble by evaluation from dataset\")\n",
    "    metrics = ensemble.evaluate_adapters_by_evaluation_from_dataset(val_datasets)  # type: ignore\n",
    "    logger.info(\"Evaluation by evaluation results:\")\n",
    "    for idx, adapter in enumerate(ensemble.adapters):\n",
    "        logger.info(f\"Adapter: {adapter.__class__.__name__}, Metrics: {metrics[idx]}\")\n",
    "\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_2():\n",
    "    logger.info(\"Evaluating ensemble by predict from dataset\")\n",
    "    metrics = ensemble.evaluate_adapters_by_predict_from_dataset(val_datasets)  # type: ignore\n",
    "    logger.info(\"Evaluation by predict results:\")\n",
    "    for idx, adapter in enumerate(ensemble.adapters):\n",
    "        logger.info(f\"Adapter: {adapter.__class__.__name__}, Metrics: {metrics[idx]}\")\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_3(m1, m2, metric_name: str):\n",
    "    logger.info(\"Comparing results from both evaluation methods\")\n",
    "    for idx, adapter in enumerate(ensemble.adapters):\n",
    "        logger.info(f\"Adapter: {adapter.__class__.__name__}\")\n",
    "        logger.info(f\"Metrics from evaluation: {m1[idx][metric_name]}\")\n",
    "        logger.info(f\"Metrics from predict: {m2[idx][metric_name]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m1 = test_1()\n",
    "    m2 = test_2()\n",
    "\n",
    "    test_3(m1, m2, \"map_50_95\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-carbucks-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
