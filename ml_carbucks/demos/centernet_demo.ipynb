{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from ml_carbucks.utils.coco import create_dataset_custom\n",
    "\n",
    "IMG_SIZE = 320\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "class CenterNetHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # Shared conv\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # Separate heads\n",
    "        self.heatmap = nn.Conv2d(256, num_classes, 1)\n",
    "        self.wh = nn.Conv2d(256, 2, 1)\n",
    "        self.offset = nn.Conv2d(256, 2, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Heatmap bias init -> lower confidence initially\n",
    "        self.heatmap.bias.data.fill_(-2.19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.shared(x)\n",
    "        return {\n",
    "            'heatmap': torch.sigmoid(self.heatmap(feat)),\n",
    "            'wh': self.wh(feat),\n",
    "            'offset': self.offset(feat),\n",
    "        }\n",
    "\n",
    "\n",
    "class CenterNet(nn.Module):\n",
    "    def __init__(self, num_classes=3, backbone_name='resnet50', pretrained=True):\n",
    "        super().__init__()\n",
    "        backbone = resnet50(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])  # C5 feature map\n",
    "        self.head = CenterNetHead(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        out = self.head(feat)\n",
    "        return out\n",
    "\n",
    "def focal_loss(pred, gt):\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "\n",
    "    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "\n",
    "    return -(pos_loss + neg_loss) / (num_pos + 1e-4)\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    hm_loss = focal_loss(preds['heatmap'], targets['heatmap'])\n",
    "    wh_loss = F.l1_loss(preds['wh'], targets['wh'], reduction='mean')\n",
    "    off_loss = F.l1_loss(preds['offset'], targets['offset'], reduction='mean')\n",
    "    return hm_loss + wh_loss + off_loss, (hm_loss, wh_loss, off_loss)\n",
    "\n",
    "\n",
    "def decode_predictions(heatmap, wh, offset, K=100):\n",
    "    batch, cat, height, width = heatmap.size()\n",
    "    heatmap = F.max_pool2d(heatmap, 3, stride=1, padding=1)\n",
    "    scores, inds = torch.topk(heatmap.view(batch, cat, -1), K)\n",
    "    ys = (inds // width).float()\n",
    "    xs = (inds % width).float()\n",
    "\n",
    "    wh = wh.view(batch, 2, -1)\n",
    "    offset = offset.view(batch, 2, -1)\n",
    "\n",
    "    xs = xs + offset[:, 0:1, :].gather(2, inds)\n",
    "    ys = ys + offset[:, 1:2, :].gather(2, inds)\n",
    "\n",
    "    w = wh[:, 0:1, :].gather(2, inds)\n",
    "    h = wh[:, 1:2, :].gather(2, inds)\n",
    "\n",
    "    x1 = xs - w / 2\n",
    "    y1 = ys - h / 2\n",
    "    x2 = xs + w / 2\n",
    "    y2 = ys + h / 2\n",
    "    return torch.stack([x1, y1, x2, y2], dim=-1), scores\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CenterNet(num_classes=3, backbone_name='resnet50', pretrained=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def encode_targets(boxes, labels, output_size, num_classes):\n",
    "    heatmap = torch.zeros((num_classes, *output_size), device=device)\n",
    "    wh = torch.zeros((2, *output_size), device=device)\n",
    "    offset = torch.zeros((2, *output_size), device=device)\n",
    "\n",
    "    # You must rescale boxes from image size â†’ output size (downsample by stride=4)\n",
    "    stride = 4  \n",
    "    for box, cls in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cx = (x1 + x2) / 2 / stride\n",
    "        cy = (y1 + y2) / 2 / stride\n",
    "        w = (x2 - x1) / stride\n",
    "        h = (y2 - y1) / stride\n",
    "        cx_int, cy_int = int(cx), int(cy)\n",
    "\n",
    "        # mark the heatmap (you can add a small gaussian, here just set 1)\n",
    "        heatmap[cls, cy_int, cx_int] = 1\n",
    "        wh[:, cy_int, cx_int] = torch.tensor([w, h], device=device)\n",
    "        offset[:, cy_int, cx_int] = torch.tensor([cx - cx_int, cy - cy_int], device=device)\n",
    "\n",
    "    return {'heatmap': heatmap, 'wh': wh, 'offset': offset}\n",
    "\n",
    "\n",
    "train_dataset = create_dataset_custom(\n",
    "    name=\"train\",\n",
    "    img_dir=Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/train\"),\n",
    "    ann_file=Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_train.json\"),\n",
    "    limit=1\n",
    ")\n",
    "from effdet.data import create_loader\n",
    "train_loader = create_loader(\n",
    "    train_dataset,\n",
    "    input_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_prefetcher=True,\n",
    "    num_workers=4,\n",
    "    pin_mem=False,\n",
    ")\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):  # just 10 for test\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Convert your COCO targets to CenterNet targets\n",
    "        batch_targets = [encode_targets(t['boxes'], t['labels'], (imgs.shape[2]//4, imgs.shape[3]//4), 3) for t in targets]\n",
    "        batch_hm = torch.stack([bt['heatmap'] for bt in batch_targets])\n",
    "        batch_wh = torch.stack([bt['wh'] for bt in batch_targets])\n",
    "        batch_off = torch.stack([bt['offset'] for bt in batch_targets])\n",
    "\n",
    "        pred = model(imgs)\n",
    "        loss, (hm_loss, wh_loss, off_loss) = compute_loss(pred, {'heatmap': batch_hm, 'wh': batch_wh, 'offset': batch_off})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f} | hm: {hm_loss.item():.4f} | wh: {wh_loss.item():.4f} | off: {off_loss.item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-carbucks-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
