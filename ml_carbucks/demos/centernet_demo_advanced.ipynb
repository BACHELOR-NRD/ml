{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a44cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config.py\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "CONFIG = {\n",
    "    \"IMG_SIZE\": 320,\n",
    "    \"BATCH_SIZE\": 8,\n",
    "    \"NUM_CLASSES\": 3,\n",
    "    \"EPOCHS\": 100,\n",
    "    \"LR\": 1e-4,\n",
    "    \"BACKBONE\": \"resnet50\",\n",
    "    \"PRETRAINED\": True,\n",
    "    \"TRAIN_DIR\": Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/train\"),\n",
    "    \"VAL_DIR\": Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/val\"),\n",
    "    \"TRAIN_ANN\": Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_train.json\"),\n",
    "    \"VAL_ANN\": Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_val.json\"),\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"CONF_THRESH\": 0.3,\n",
    "    \"NMS_IOU\": 0.5,\n",
    "    \"TOPK\": 100,\n",
    "    \"GAUSSIAN_RADIUS\": 2,\n",
    "}\n",
    "\n",
    "# dataset.py\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from ml_carbucks.utils.coco import create_dataset_custom\n",
    "\n",
    "# class DamageDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, img_dir, ann_file, img_size, augment=False, limit=None):\n",
    "#         self.dataset = create_dataset_custom(\n",
    "#             name=\"damage\",\n",
    "#             img_dir=img_dir,\n",
    "#             ann_file=ann_file,\n",
    "#             limit=limit\n",
    "#         )\n",
    "#         self.img_size = img_size\n",
    "#         self.augment = augment\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Resize((img_size, img_size)),\n",
    "#         ])\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "#     def __getitem__(self, idx):\n",
    "#         img, target = self.dataset[idx]\n",
    "#         img = self.transform(img)\n",
    "#         # convert target fields to tensors\n",
    "#         target_t = {\n",
    "#             'bbox': torch.tensor(target['bbox'], dtype=torch.float32),\n",
    "#             'cls': torch.tensor(target['cls'], dtype=torch.long)\n",
    "#         }\n",
    "#         return img, target_t\n",
    "\n",
    "# dataset_aug.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from ml_carbucks.utils.coco import create_dataset_custom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DamageDatasetAug(Dataset):\n",
    "    def __init__(self, img_dir, ann_file, img_size, augment=True, limit=None):\n",
    "        self.dataset = create_dataset_custom(\n",
    "            name=\"damage\", img_dir=img_dir, ann_file=ann_file, limit=limit\n",
    "        )\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "\n",
    "        normalize = A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0\n",
    "        )\n",
    "\n",
    "        self.train_transform = A.Compose(\n",
    "            [\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5\n",
    "                ),\n",
    "                normalize,\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_transform = A.Compose(\n",
    "            [\n",
    "                A.Resize(img_size, img_size),\n",
    "                normalize,\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = self.dataset[idx]\n",
    "        bboxes = target[\"bbox\"]\n",
    "        labels = target[\"cls\"]\n",
    "\n",
    "        transform = self.train_transform if self.augment else self.val_transform\n",
    "        transformed = transform(image=np.array(img), bboxes=bboxes, class_labels=labels)\n",
    "        img = transformed[\"image\"]  # <-- now float32 automatically\n",
    "        bboxes = torch.tensor(transformed[\"bboxes\"], dtype=torch.float32)\n",
    "        labels = torch.tensor(transformed[\"class_labels\"], dtype=torch.long)\n",
    "\n",
    "        return img, {\"bbox\": bboxes, \"cls\": labels}\n",
    "\n",
    "\n",
    "# model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "\n",
    "class CenterNetHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.heatmap = nn.Conv2d(256, num_classes, 1)\n",
    "        self.wh = nn.Conv2d(256, 2, 1)\n",
    "        self.offset = nn.Conv2d(256, 2, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        self.heatmap.bias.data.fill_(-2.19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.shared(x)\n",
    "        return {\n",
    "            \"heatmap\": torch.sigmoid(self.heatmap(feat)),\n",
    "            \"wh\": self.wh(feat),\n",
    "            \"offset\": self.offset(feat),\n",
    "        }\n",
    "\n",
    "\n",
    "class CenterNet(nn.Module):\n",
    "    def __init__(self, num_classes=3, backbone_name=\"resnet50\", pretrained=True):\n",
    "        super().__init__()\n",
    "        backbone = resnet50(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.head = CenterNetHead(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return self.head(feat)\n",
    "\n",
    "\n",
    "# losses.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def focal_loss(pred, gt):\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "\n",
    "    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.sum()\n",
    "    return -(pos_loss.sum() + neg_loss.sum()) / (num_pos + 1e-4)\n",
    "\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    hm_loss = focal_loss(preds[\"heatmap\"], targets[\"heatmap\"])\n",
    "    wh_loss = F.smooth_l1_loss(preds[\"wh\"], targets[\"wh\"], reduction=\"mean\")\n",
    "    off_loss = F.smooth_l1_loss(preds[\"offset\"], targets[\"offset\"], reduction=\"mean\")\n",
    "    return hm_loss + wh_loss + off_loss, (hm_loss, wh_loss, off_loss)\n",
    "\n",
    "\n",
    "# utils.py\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def draw_gaussian_2d(heatmap, cx, cy, sigma):\n",
    "    \"\"\"Draw a 2D Gaussian on the heatmap centered at (cx, cy).\"\"\"\n",
    "    tmp_size = int(3 * sigma)\n",
    "    mu_x, mu_y = int(cx), int(cy)\n",
    "    H, W = heatmap.shape[-2:]\n",
    "\n",
    "    ul = [max(0, mu_x - tmp_size), max(0, mu_y - tmp_size)]\n",
    "    br = [min(W, mu_x + tmp_size + 1), min(H, mu_y + tmp_size + 1)]\n",
    "\n",
    "    size = 2 * tmp_size + 1\n",
    "    x = torch.arange(0, size, dtype=torch.float32, device=heatmap.device)\n",
    "    y = x[:, None]\n",
    "    g = torch.exp(-((x - tmp_size) ** 2 + (y - tmp_size) ** 2) / (2 * sigma**2))\n",
    "\n",
    "    # crop g to match valid region in heatmap\n",
    "    g_x = max(0, -(mu_x - tmp_size)), min(br[0] - ul[0], size)\n",
    "    g_y = max(0, -(mu_y - tmp_size)), min(br[1] - ul[1], size)\n",
    "\n",
    "    heatmap_region = heatmap[ul[1] : br[1], ul[0] : br[0]]\n",
    "    g_region = g[g_y[0] : g_y[1], g_x[0] : g_x[1]]\n",
    "\n",
    "    # handle rare mismatch by clipping dynamically\n",
    "    hH, hW = heatmap_region.shape\n",
    "    gH, gW = g_region.shape\n",
    "    minH, minW = min(hH, gH), min(hW, gW)\n",
    "\n",
    "    heatmap[ul[1] : ul[1] + minH, ul[0] : ul[0] + minW] = torch.max(\n",
    "        heatmap[ul[1] : ul[1] + minH, ul[0] : ul[0] + minW], g_region[:minH, :minW]\n",
    "    )\n",
    "\n",
    "\n",
    "def encode_targets_vectorized(\n",
    "    batch_boxes, batch_labels, output_size, num_classes, stride, sigma=2\n",
    "):\n",
    "    \"\"\"\n",
    "    batch_boxes: list of tensors [num_boxes, 4] per image\n",
    "    batch_labels: list of tensors [num_boxes] per image\n",
    "    returns: dict of tensors [B, C, H, W] heatmap, wh, offset\n",
    "    \"\"\"\n",
    "    B = len(batch_boxes)\n",
    "    H, W = output_size\n",
    "    device = batch_boxes[0].device\n",
    "\n",
    "    heatmaps = torch.zeros(B, num_classes, H, W, device=device)\n",
    "    wh_maps = torch.zeros(B, 2, H, W, device=device)\n",
    "    offset_maps = torch.zeros(B, 2, H, W, device=device)\n",
    "\n",
    "    for b in range(B):\n",
    "        boxes = batch_boxes[b]\n",
    "        labels = batch_labels[b]\n",
    "        if boxes.numel() == 0:\n",
    "            continue\n",
    "        cx = (boxes[:, 0] + boxes[:, 2]) / 2 / stride\n",
    "        cy = (boxes[:, 1] + boxes[:, 3]) / 2 / stride\n",
    "        w = (boxes[:, 2] - boxes[:, 0]) / stride\n",
    "        h = (boxes[:, 3] - boxes[:, 1]) / stride\n",
    "        cx_int = cx.long()\n",
    "        cy_int = cy.long()\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            cls = labels[i]\n",
    "            if 0 <= cx_int[i] < W and 0 <= cy_int[i] < H:\n",
    "                draw_gaussian_2d(heatmaps[b, cls], cx[i], cy[i], sigma)\n",
    "                wh_maps[b, :, cy_int[i], cx_int[i]] = torch.tensor(\n",
    "                    [w[i], h[i]], device=device\n",
    "                )\n",
    "                offset_maps[b, :, cy_int[i], cx_int[i]] = torch.tensor(\n",
    "                    [cx[i] - cx_int[i], cy[i] - cy_int[i]], device=device\n",
    "                )\n",
    "\n",
    "    return {\"heatmap\": heatmaps, \"wh\": wh_maps, \"offset\": offset_maps}\n",
    "\n",
    "\n",
    "def encode_targets(boxes, labels, output_size, num_classes, stride, radius=2):\n",
    "    heatmap = torch.zeros((num_classes, *output_size))\n",
    "    wh = torch.zeros((2, *output_size))\n",
    "    offset = torch.zeros((2, *output_size))\n",
    "\n",
    "    def draw_gaussian(hm, x, y, radius):\n",
    "        diameter = 2 * radius + 1\n",
    "        gaussian = torch.exp(\n",
    "            -(\n",
    "                (torch.arange(diameter).view(-1, 1) - radius) ** 2\n",
    "                + (torch.arange(diameter).view(1, -1) - radius) ** 2\n",
    "            )\n",
    "            / (2 * (radius / 3) ** 2)\n",
    "        )\n",
    "        x0 = max(0, x - radius)\n",
    "        y0 = max(0, y - radius)\n",
    "        x1 = min(hm.shape[1], x + radius + 1)\n",
    "        y1 = min(hm.shape[0], y + radius + 1)\n",
    "        hm[y0:y1, x0:x1] = torch.max(hm[y0:y1, x0:x1], gaussian[: y1 - y0, : x1 - x0])\n",
    "\n",
    "    H, W = output_size\n",
    "    for box, cls in zip(boxes, labels):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cx = (x1 + x2) / 2 / stride\n",
    "        cy = (y1 + y2) / 2 / stride\n",
    "        w = (x2 - x1) / stride\n",
    "        h = (y2 - y1) / stride\n",
    "        cx_int, cy_int = int(cx), int(cy)\n",
    "        if 0 <= cx_int < W and 0 <= cy_int < H:\n",
    "            draw_gaussian(heatmap[cls], cx_int, cy_int, radius)\n",
    "            wh[:, cy_int, cx_int] = torch.tensor([w, h])\n",
    "            offset[:, cy_int, cx_int] = torch.tensor([cx - cx_int, cy - cy_int])\n",
    "    return {\"heatmap\": heatmap, \"wh\": wh, \"offset\": offset}\n",
    "\n",
    "\n",
    "def decode_predictions(preds, conf_thresh=0.3, stride=32, K=100, nms_kernel=3):\n",
    "    heatmap, wh, offset = preds[\"heatmap\"], preds[\"wh\"], preds[\"offset\"]\n",
    "    batch, cat, H, W = heatmap.shape\n",
    "    pooled = F.max_pool2d(heatmap, nms_kernel, stride=1, padding=nms_kernel // 2)\n",
    "    heatmap = heatmap * (pooled == heatmap).float()\n",
    "\n",
    "    boxes_list, scores_list, labels_list = [], [], []\n",
    "\n",
    "    for b in range(batch):\n",
    "        for c in range(cat):\n",
    "            hm_flat = heatmap[b, c].view(-1)\n",
    "            topk_scores, topk_inds = torch.topk(hm_flat, K)\n",
    "            mask = topk_scores > conf_thresh\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            topk_scores = topk_scores[mask]\n",
    "            topk_inds = topk_inds[mask]\n",
    "            ys = (topk_inds // W).float()\n",
    "            xs = (topk_inds % W).float()\n",
    "            w = wh[b, 0].view(-1)[topk_inds]\n",
    "            h = wh[b, 1].view(-1)[topk_inds]\n",
    "            off_x = offset[b, 0].view(-1)[topk_inds]\n",
    "            off_y = offset[b, 1].view(-1)[topk_inds]\n",
    "            xs = xs + off_x\n",
    "            ys = ys + off_y\n",
    "            x1 = (xs - w / 2) * stride\n",
    "            y1 = (ys - h / 2) * stride\n",
    "            x2 = (xs + w / 2) * stride\n",
    "            y2 = (ys + h / 2) * stride\n",
    "            boxes_list.append(torch.stack([x1, y1, x2, y2], dim=-1))\n",
    "            scores_list.append(topk_scores)\n",
    "            labels_list.append(torch.full_like(topk_scores, c, dtype=torch.int))\n",
    "\n",
    "    if len(boxes_list) == 0:\n",
    "        return (\n",
    "            torch.empty((0, 4)),\n",
    "            torch.empty((0,)),\n",
    "            torch.empty((0,), dtype=torch.int),\n",
    "        )\n",
    "\n",
    "    boxes = torch.cat(boxes_list)\n",
    "    scores = torch.cat(scores_list)\n",
    "    labels = torch.cat(labels_list)\n",
    "    keep = torchvision.ops.nms(boxes, scores, iou_threshold=0.5)\n",
    "    return boxes[keep], scores[keep], labels[keep]\n",
    "\n",
    "\n",
    "# train_production.py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.models import resnet50\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Config ---\n",
    "IMG_SIZE = CONFIG[\"IMG_SIZE\"]\n",
    "BATCH_SIZE = CONFIG[\"BATCH_SIZE\"]\n",
    "NUM_CLASSES = CONFIG[\"NUM_CLASSES\"]\n",
    "EPOCHS = CONFIG[\"EPOCHS\"]\n",
    "LR = CONFIG[\"LR\"]\n",
    "CHECKPOINT_DIR = Path(\"./checkpoints\")\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GAUSSIAN_RADIUS = 2\n",
    "\n",
    "\n",
    "# --- Model ---\n",
    "class CenterNetHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.heatmap = nn.Conv2d(256, num_classes, 1)\n",
    "        self.wh = nn.Conv2d(256, 2, 1)\n",
    "        self.offset = nn.Conv2d(256, 2, 1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        self.heatmap.bias.data.fill_(-2.19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.shared(x)\n",
    "        return {\n",
    "            \"heatmap\": torch.sigmoid(self.heatmap(feat)),\n",
    "            \"wh\": self.wh(feat),\n",
    "            \"offset\": self.offset(feat),\n",
    "        }\n",
    "\n",
    "\n",
    "class CenterNet(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super().__init__()\n",
    "        backbone = resnet50(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        self.head = CenterNetHead(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return self.head(feat)\n",
    "\n",
    "\n",
    "# --- Loss ---\n",
    "def focal_loss(pred, gt):\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "\n",
    "    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.float().sum()\n",
    "    return -(pos_loss.sum() + neg_loss.sum()) / (num_pos + 1e-4)\n",
    "\n",
    "\n",
    "def compute_loss(preds, targets):\n",
    "    hm_loss = focal_loss(preds[\"heatmap\"], targets[\"heatmap\"])\n",
    "    wh_loss = F.l1_loss(preds[\"wh\"], targets[\"wh\"], reduction=\"mean\")\n",
    "    off_loss = F.l1_loss(preds[\"offset\"], targets[\"offset\"], reduction=\"mean\")\n",
    "    return hm_loss + wh_loss + off_loss, (hm_loss, wh_loss, off_loss)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    targets = []\n",
    "    for sample in batch:\n",
    "        img, target = sample\n",
    "        imgs.append(img)\n",
    "        targets.append(target)\n",
    "    imgs = torch.stack(imgs, 0)\n",
    "    return imgs, targets\n",
    "\n",
    "\n",
    "# --- Dataset & Loader ---\n",
    "train_dataset = DamageDatasetAug(\n",
    "    img_dir=Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/train\"),\n",
    "    ann_file=Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_train.json\"),\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=True,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# --- Model & Optimizer ---\n",
    "model = CenterNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = torch.cuda.amp.GradScaler()  # mixed precision\n",
    "\n",
    "# --- Precompute stride / output size ---\n",
    "with torch.no_grad():\n",
    "    dummy = torch.zeros(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "    pred = model(dummy)\n",
    "target_h, target_w = pred[\"heatmap\"].shape[2], pred[\"heatmap\"].shape[3]\n",
    "stride = IMG_SIZE // target_h\n",
    "\n",
    "# --- Training Loop ---\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     running_loss = 0\n",
    "#     for (imgs, targets) in tqdm(train_loader):\n",
    "#         imgs = imgs.to(DEVICE)\n",
    "#         batch_boxes = [t['bbox'].to(DEVICE) for t in targets]\n",
    "#         batch_labels = [t['cls'].to(DEVICE) for t in targets]\n",
    "\n",
    "#         # Encode targets vectorized\n",
    "#         batch_targets = encode_targets_vectorized(\n",
    "#             batch_boxes, batch_labels, output_size=(target_h, target_w),\n",
    "#             num_classes=NUM_CLASSES, stride=stride, sigma=GAUSSIAN_RADIUS\n",
    "#         )\n",
    "#         optimizer.zero_grad()\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             preds = model(imgs)\n",
    "#             loss, (hm_loss, wh_loss, off_loss) = compute_loss(preds, batch_targets)\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "#         running_loss += loss.item()\n",
    "#     avg_loss = running_loss / len(train_loader)\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | hm: {hm_loss.item():.4f} | wh: {wh_loss.item():.4f} | off: {off_loss.item():.4f}\")\n",
    "#     # --- Save checkpoint every 5 epochs ---\n",
    "#     if (epoch+1) % 5 == 0:\n",
    "#         ckpt_path = CHECKPOINT_DIR / f\"centernet_epoch{epoch+1}.pth\"\n",
    "#         torch.save({\n",
    "#             \"epoch\": epoch+1,\n",
    "#             \"model_state\": model.state_dict(),\n",
    "#             \"optimizer_state\": optimizer.state_dict()\n",
    "#         }, ckpt_path)\n",
    "#         print(f\"Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "\n",
    "model = CenterNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = torch.cuda.amp.GradScaler()  # mixed precision\n",
    "\n",
    "# load model if exists\n",
    "latest_ckpt = (\n",
    "    sorted(CHECKPOINT_DIR.glob(\"centernet_epoch*.pth\"))[-1]\n",
    "    if list(CHECKPOINT_DIR.glob(\"centernet_epoch*.pth\"))\n",
    "    else None\n",
    ")\n",
    "if latest_ckpt:\n",
    "    checkpoint = torch.load(latest_ckpt, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    print(f\"Resumed from checkpoint: {latest_ckpt} at epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "all_preds, all_gts = [], []\n",
    "\n",
    "val_dataset = DamageDatasetAug(\n",
    "    img_dir=Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/val\"),\n",
    "    ann_file=Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_val.json\"),\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "all_preds = []\n",
    "all_gts = []\n",
    "\n",
    "for imgs, targets in val_loader:\n",
    "    imgs = imgs.to(DEVICE)\n",
    "    preds = model(imgs)\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        # Decode predictions for a single image\n",
    "        boxes_i, scores_i, labels_i = decode_predictions(\n",
    "            {k: v[i : i + 1] for k, v in preds.items()}, conf_thresh=0.05, stride=stride\n",
    "        )\n",
    "\n",
    "        # Make sure tensors are correct dtype and on CPU\n",
    "        if len(boxes_i) == 0:\n",
    "            boxes_i = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            scores_i = torch.zeros((0,), dtype=torch.float32)\n",
    "            labels_i = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            boxes_i = boxes_i.float()\n",
    "            scores_i = scores_i.float()\n",
    "            labels_i = labels_i.long()\n",
    "\n",
    "        all_preds.append(\n",
    "            {\"boxes\": boxes_i.cpu(), \"scores\": scores_i.cpu(), \"labels\": labels_i.cpu()}\n",
    "        )\n",
    "\n",
    "        # Ground truth\n",
    "        gt_boxes = targets[i][\"bbox\"]\n",
    "        gt_labels = targets[i][\"cls\"]\n",
    "        if len(gt_boxes) == 0:\n",
    "            gt_boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            gt_labels = torch.zeros((0,), dtype=torch.int64)\n",
    "        else:\n",
    "            gt_boxes = gt_boxes.float()\n",
    "            gt_labels = gt_labels.long()\n",
    "\n",
    "        all_gts.append({\"boxes\": gt_boxes.cpu(), \"labels\": gt_labels.cpu()})\n",
    "\n",
    "# Compute metric\n",
    "metric = MeanAveragePrecision()\n",
    "metric.update(all_preds, all_gts)\n",
    "result = metric.compute()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
