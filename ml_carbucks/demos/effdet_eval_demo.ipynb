{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d96a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from effdet import create_model, create_loader, create_evaluator\n",
    "from effdet.data import resolve_input_config\n",
    "try:\n",
    "    from timm.layers import set_layer_config\n",
    "except ImportError:\n",
    "    from timm.models.layers import set_layer_config\n",
    "from ml_carbucks.utils import create_dataset_custom\n",
    "from effdet.anchors import Anchors, AnchorLabeler\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 320\n",
    "NUM_CLASSES = None\n",
    "EPOCHS = 100\n",
    "extra_args = dict(image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "bench_train = create_model(\n",
    "    model_name='tf_efficientdet_d2', \n",
    "    bench_task='train',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    pretrained=True,\n",
    "    redundant_bias=None,\n",
    "    soft_nms=None,\n",
    "    checkpoint_path='',\n",
    "    checkpoint_ema=False,\n",
    "    **extra_args,\n",
    ")\n",
    "model_train_config = bench_train.config\n",
    "labeler = AnchorLabeler(\n",
    "    Anchors.from_config(model_train_config),\n",
    "    model_train_config.num_classes,\n",
    "    match_threshold=0.5,\n",
    ")\n",
    "\n",
    "train_dataset = create_dataset_custom(\n",
    "    name=\"val\",\n",
    "    # img_dir=Path(\"/home/bachelor/ml-carbucks/data/mscoco/val2017\"),\n",
    "    # ann_file=Path(\"/home/bachelor/ml-carbucks/data/mscoco/annotations/instances_val2017.json\"),\n",
    "    img_dir=Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/val\"),\n",
    "    ann_file=Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_val.json\"),\n",
    ")\n",
    "\n",
    "train_input_config = resolve_input_config({}, model_train_config)\n",
    "train_loader = create_loader(\n",
    "    train_dataset,\n",
    "    input_size=train_input_config['input_size'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_prefetcher=True,\n",
    "    interpolation=train_input_config['interpolation'],\n",
    "    mean=train_input_config['mean'],\n",
    "    std=train_input_config['std'],\n",
    "    num_workers=4,\n",
    "    pin_mem=False,\n",
    "    anchor_labeler=labeler,\n",
    ")\n",
    "\n",
    "for param in bench_train.model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, bench_train.parameters()), lr=1e-4\n",
    ")\n",
    "\n",
    "bench_train = bench_train.cuda()\n",
    "# set_layer_config(bench_train, 'fuse_bn', True)\n",
    "bench_train.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (input, target) in enumerate(train_loader):\n",
    "        output = bench_train(input, target)\n",
    "        loss = output['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "train_state_dict = bench_train.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "\n",
    "bench_pred = create_model(\n",
    "    model_name='tf_efficientdet_d2', \n",
    "    bench_task='predict',\n",
    "    num_classes=NUM_CLASSES,\n",
    "    pretrained=True,\n",
    "    redundant_bias=None,\n",
    "    soft_nms=None,\n",
    "    checkpoint_path='',\n",
    "    checkpoint_ema=False,\n",
    "    **extra_args,\n",
    ")\n",
    "bench_pred.model.load_state_dict(train_state_dict)\n",
    "model_pred_config = bench_pred.config\n",
    "bench_pred = bench_pred.cuda()\n",
    "\n",
    "val_dataset = create_dataset_custom(\n",
    "    name=\"val\",\n",
    "    # img_dir=Path(\"/home/bachelor/ml-carbucks/data/mscoco/val2017\"),\n",
    "    # ann_file=Path(\"/home/bachelor/ml-carbucks/data/mscoco/annotations/instances_val2017.json\"),\n",
    "    img_dir=Path(\"/home/bachelor/ml-carbucks/data/car_dd/images/val\"),\n",
    "    ann_file=Path(\"/home/bachelor/ml-carbucks/data/car_dd/instances_val.json\"),\n",
    ")\n",
    "\n",
    "input_config = resolve_input_config({}, model_pred_config)\n",
    "loader = create_loader(\n",
    "    val_dataset,\n",
    "    input_size=input_config['input_size'],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_prefetcher=True,\n",
    "    interpolation=input_config['interpolation'],\n",
    "    mean=input_config['mean'],\n",
    "    std=input_config['std'],\n",
    "    num_workers=4,\n",
    "    pin_mem=False\n",
    ")\n",
    "evaluator = create_evaluator(\"coco\", val_dataset, pred_yxyx=False)\n",
    "bench_pred.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (input, target) in enumerate(loader):\n",
    "        output = bench_pred(input, img_info=target)\n",
    "        evaluator.add_predictions(output, target)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Eval {i}/{len(loader)}\")\n",
    "\n",
    "metrics = evaluator.evaluate()\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-carbucks-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
