{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea205253",
   "metadata": {},
   "source": [
    "***This notebook trains our 4 adapters on the same dataset and compares their results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b66893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pprint import pprint as print\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Literal, Optional, Tuple\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from effdet import create_model, create_loader\n",
    "from effdet.data import resolve_input_config, resolve_fill_color\n",
    "from effdet.bench import DetBenchPredict  # noqa F401\n",
    "from effdet.data.transforms import ResizePad, ImageToNumpy, Compose\n",
    "from timm.optim._optim_factory import create_optimizer_v2\n",
    "\n",
    "from ml_carbucks.utils.preprocessing import create_clean_loader, create_transforms, preprocess_images\n",
    "from ml_carbucks.utils.inference import plot_img_pred_subplots as psp\n",
    "from ml_carbucks import DATA_DIR, RESULTS_DIR\n",
    "from ml_carbucks.utils.postprocessing import (\n",
    "    postprocess_prediction_nms,\n",
    "    postprocess_evaluation_results,\n",
    ")\n",
    "from ml_carbucks.utils.result_saver import ResultSaver\n",
    "from ml_carbucks.adapters.BaseDetectionAdapter import (\n",
    "    ADAPTER_METRICS,\n",
    "    BaseDetectionAdapter,\n",
    "    ADAPTER_PREDICTION,\n",
    ")\n",
    "from ml_carbucks.patches.effdet import (\n",
    "    CocoStatsEvaluator,\n",
    "    ConcatDetectionDataset,\n",
    "    create_dataset_custom,\n",
    ")\n",
    "from ml_carbucks.utils.conversions import convert_yolo_to_coco\n",
    "from ml_carbucks.utils.logger import setup_logger\n",
    "import json\n",
    "import datetime as dt\n",
    "from ml_carbucks.adapters.EfficientDetAdapter import EfficientDetAdapter\n",
    "from ml_carbucks.adapters.FasterRcnnAdapter import FasterRcnnAdapter\n",
    "from ml_carbucks.adapters.UltralyticsAdapter import (\n",
    "    YoloUltralyticsAdapter,\n",
    "    RtdetrUltralyticsAdapter,\n",
    ")\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "\n",
    "DATASET_TUPLE_TYPE = tuple[str | Path, str | Path]\n",
    "\n",
    "classes = [\"scratch\", \"dent\", \"crack\"]\n",
    "\n",
    "cardd_dataset_train: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"car_dd\" / \"images\" / \"train\",\n",
    "    DATA_DIR / \"car_dd\" / \"annotations\" /\"instances_train_curated.json\",\n",
    ")\n",
    "cardd_dataset_val: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"car_dd\" / \"images\" / \"val\",\n",
    "    DATA_DIR / \"car_dd\" / \"annotations\" /\"instances_val_curated.json\",\n",
    ")\n",
    "\n",
    "carbucks_raw_dataset_train: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks\" / \"images\" / \"train\",\n",
    "    DATA_DIR / \"carbucks\" / \"instances_train_curated.json\",\n",
    ")\n",
    "carbucks_raw_dataset_val: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks\" / \"images\" / \"val\",\n",
    "    DATA_DIR / \"carbucks\" / \"instances_val_curated.json\",\n",
    ")\n",
    "carbucks_clean_dataset_train: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks_cleaned\" / \"images\" / \"train\",\n",
    "    DATA_DIR / \"carbucks_cleaned\" / \"instances_train_curated.json\",\n",
    ")\n",
    "carbucks_clean_dataset_val: DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks_cleaned\" / \"images\" / \"val\",\n",
    "    DATA_DIR / \"carbucks_cleaned\" / \"instances_val_curated.json\",\n",
    ")\n",
    "carbucks_balanced_dataset_train : DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks_balanced\" / \"images\" / \"train\",\n",
    "    DATA_DIR / \"carbucks_balanced\" / \"instances_train_curated.json\",\n",
    ")\n",
    "carbucks_balanced_dataset_val : DATASET_TUPLE_TYPE = (\n",
    "    DATA_DIR / \"carbucks_balanced\" / \"images\" / \"val\",\n",
    "    DATA_DIR / \"carbucks_balanced\" / \"instances_val_curated.json\",\n",
    ")\n",
    "\n",
    "mvp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "EXPERIMENT_NAME = \"car_dd_plus_carbucks_clean\"\n",
    "RUNTIME = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RESULTS_ROOT = RESULTS_DIR / \"debug\" / \"adapter_training\" / f\"{EXPERIMENT_NAME}_{RUNTIME}\"\n",
    "RESULTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_datasets = [cardd_dataset_train, carbucks_clean_dataset_train]\n",
    "val_datasets = [cardd_dataset_val, carbucks_clean_dataset_val]\n",
    "\n",
    "def run_adapter(\n",
    "    adapter_cls,\n",
    "    name: str,\n",
    "    *,\n",
    "    img_size: int = 512,\n",
    "    epochs: int = 10,\n",
    "    batch_size: int = 8,\n",
    "    extra_params: dict | None = None,\n",
    "):\n",
    "    params = {\"classes\": classes, \"img_size\": img_size, \"epochs\": epochs, \"batch_size\": batch_size}\n",
    "    if extra_params:\n",
    "        params.update(extra_params)\n",
    "\n",
    "    adapter = adapter_cls(**params).setup()\n",
    "    adapter.fit(train_datasets)\n",
    "    metrics = adapter.evaluate(val_datasets)\n",
    "\n",
    "    save_dir = RESULTS_ROOT / name\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    adapter.save(save_dir, prefix=f\"{name}_\")\n",
    "    (save_dir / \"metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "    print(f\"{name}: {metrics}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientdet_metrics = run_adapter(\n",
    "    EfficientDetAdapter,\n",
    "    name=\"efficientdet_inbuild_optuna\",\n",
    "    extra_params={\n",
    "        \"img_size\": 384,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 30,\n",
    "        \"optimizer\": \"momentum\",\n",
    "        \"lr\": 4.175231383082291e-03,\n",
    "        \"weight_decay\": 5.1636910035878785e-05,\n",
    "        \"confidence_threshold\": 0.04424559135759042,\n",
    "        \"loader\": \"inbuild\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterrcnn_metrics = run_adapter(\n",
    "    FasterRcnnAdapter,\n",
    "    name=\"fasterrcnn_resnet50\",\n",
    "    img_size=512,\n",
    "    epochs=10,\n",
    "    batch_size=4,\n",
    "    extra_params={\n",
    "        \"weights\": \"DEFAULT\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"training_augmentations\": True,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f160fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_metrics = run_adapter(\n",
    "    YoloUltralyticsAdapter,\n",
    "    name=\"ultralytics_yolo11l\",\n",
    "    img_size=640,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    extra_params={\n",
    "        \"weights\": Path(\"/home/bachelor/ml-carbucks/yolo11l.pt\"),\n",
    "        \"training_save\": True,\n",
    "        \"project_dir\": RESULTS_ROOT / \"ultralytics\",\n",
    "        \"name\": \"yolo11l_cardd_carbucks_clean\",\n",
    "        \"training_augmentations\": True,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdetr_metrics = run_adapter(\n",
    "    RtdetrUltralyticsAdapter,\n",
    "    name=\"ultralytics_rtdetr_l_optuna\",\n",
    "    extra_params={\n",
    "        \"img_size\": 384,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 14,\n",
    "        \"lr\": 2.4406853367265458e-04,\n",
    "        \"momentum\": 0.941920609133938,\n",
    "        \"weight_decay\": 1.7052972123891876e-04,\n",
    "        \"optimizer\": \"NAdam\",\n",
    "        \"weights\": Path(\"/home/bachelor/ml-carbucks/rtdetr-l.pt\"),\n",
    "        \"training_save\": True,\n",
    "        \"project_dir\": RESULTS_ROOT / \"ultralytics\",\n",
    "        \"name\": \"rtdetr_cardd_carbucks_clean_optuna\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    \"efficientdet_inbuild\": efficientdet_metrics,\n",
    "    \"fasterrcnn_resnet50\": fasterrcnn_metrics,\n",
    "    \"ultralytics_yolo11l\": yolo_metrics,\n",
    "    \"ultralytics_rtdetr_l\": rtdetr_metrics,\n",
    "}\n",
    "\n",
    "for name, metrics in all_metrics.items():\n",
    "    print(f\"{name}: mAP50={metrics['map_50']:.4f}, mAP50-95={metrics['map_50_95']:.4f}\")\n",
    "\n",
    "import json\n",
    "summary_path = RESULTS_ROOT / \"metrics_summary.json\"\n",
    "summary_path.write_text(json.dumps(all_metrics, indent=2))\n",
    "print(f\"Saved summary to {summary_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
